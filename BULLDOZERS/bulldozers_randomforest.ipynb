{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An attempt to solve the bulldozers dataset in Kaggle using Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Importing requisite libraries\n",
    "import pandas as pd,numpy as np,re,datetime,os,math,csv\n",
    "from IPython.display import display\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn import metrics\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### PARAMETERS EXPLANATION\n",
    "*Setting Low_memory to prevent memory crunch in guessing the datatype\n",
    "\n",
    "*Parse date converts string date to a date format from (11/16/2006 0:00) to (2006-11-16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "df_raw = pd.read_csv('data/train.csv',low_memory=False ,parse_dates=['saledate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Checking the size of the dataset and the number of columns\n",
    "print (df_raw.shape)\n",
    "display(df_raw.describe(include='all').transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#EVALUATION METRIC - RMSLE - root mean squared Log error\n",
    "#Taking the log of the dependent variable\n",
    "df_raw.SalePrice  = np.log(df_raw.SalePrice)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_datepart(df_raw,'saledate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (df_raw.head(5)['UsageBand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_to_cats(df_raw)\n",
    "print (df_raw.head(5)['UsageBand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#setting the order for the categories\n",
    "display(df_raw.UsageBand.cat.categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_raw.UsageBand.cat.set_categories(['High','Medium','Low'],ordered = True,inplace = True)\n",
    "df_raw.UsageBand = df_raw.UsageBand.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (df_raw.head(5)['UsageBand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Percentage of values which are null\n",
    "display(df_raw.isnull().sum().sort_index()/len(df_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Saving all the precproceesing work in a feather file for later access\n",
    "os.makedirs('tmp', exist_ok=True)\n",
    "df_raw.to_feather('tmp/bulldozers-raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### START FROM HERE - PREPROCESSED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Working_df = pd.read_feather('tmp/bulldozers-raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Splitting into numeric and non numeric data types\n",
    "quantitative = [f for f in Working_df.columns if is_numeric_dtype(Working_df[f])]\n",
    "qualitative = Working_df.columns.difference(quantitative)\n",
    "#Do not replace and Id column and the dependent variable\n",
    "quantitative.remove('SalesID')\n",
    "quantitative.remove('SalePrice')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### REPLACE MISSING VALUES OF NUMERIC DTYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in quantitative:\n",
    "    fix_missing(Working_df,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### REPLACE CATEGORICAL VALUES WITH THEIR CODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in qualitative:\n",
    "    numericalize(Working_df,i)\n",
    "    #dropping the categorical column after replacing\n",
    "    Working_df.drop(i,axis =1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GETTING THE Y VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = Working_df.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calling the Random forest regressor\n",
    "m = RandomForestRegressor(n_jobs=-1)\n",
    "m.fit(Working_df, y)\n",
    "m.score(Working_df, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting a sample of the total data for a better runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_Sample(df,n): return df.sample(n)\n",
    "Working_df1 = get_Sample(Working_df,30000)\n",
    "y1 = Working_df1['SalePrice']\n",
    "Working_df1.drop('SalePrice',axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extracting subset for processing\n",
    "def split_vals(a,n): return a[:n].copy(), a[n:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Using splitvals for subsetting\n",
    "\n",
    "n_valid = 12000  # same as Kaggle's test set size\n",
    "\n",
    "n_trn = len(Working_df1)-n_valid\n",
    "raw_train, raw_valid = split_vals(Working_df1, n_trn)\n",
    "X_train, X_valid = split_vals(Working_df1, n_trn)\n",
    "y_train, y_valid = split_vals(y1, n_trn)\n",
    "\n",
    "X_train.shape, y_train.shape, X_valid.shape,y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(x,y): return math.sqrt(((x-y)**2).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_score(m):\n",
    "    res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_valid), y_valid),\n",
    "                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calling the Random forest regressor\n",
    "\n",
    "m = RandomForestRegressor(n_jobs=-1)\n",
    "%time m.fit(X_train,y_train)\n",
    "print_score(m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying Subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation = 12000\n",
    "n_trn = len(Working_df)-12000\n",
    "X_train, X_valid = split_vals(Working_df, n_trn)\n",
    "y_train, y_valid = split_vals(y, n_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set_rf_samples(20000)\n",
    "# reset_rf_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Base model with training and validation set\n",
    "m = RandomForestRegressor(n_jobs=-1,n_estimators=40,max_features=0.5)\n",
    "%time m.fit(X_train,y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b=np.stack([i.predict(X_valid) for i in m.estimators_])\n",
    "#Default is 10 estimators and each estimator produces an array of n values(based on the sampling) (X_train)\n",
    "#Average of the 10 estimators for each of them would be the output from the random forest model\n",
    "#For the last record the random forest output would be\n",
    "b[:,11999],np.mean(b[:,11999]),list(y_valid)[11999]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot([metrics.r2_score(y_valid, np.mean(b[:i+1], axis=0)) for i in range(10)]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the Parallel core to speed up the output (ONLY ON UBUNTU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time preds = np.stack([t.predict(X_valid) for t in m.estimators_])\n",
    "np.mean(preds[:,0]), np.std(preds[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_preds(t): return t.predict(X_valid)\n",
    "def parallel_trees(m, fn, n_jobs=2):\n",
    "        return list(ProcessPoolExecutor(n_jobs).map(fn, m.estimators_))\n",
    "%time preds = np.stack(parallel_trees(m, get_preds))\n",
    "np.mean(preds[:,0]), np.std(preds[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EVALUATING THE OUTPUT BY USING STD DEVIATION OF OUTPUT (confidence based on how it deviates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds.shape\n",
    "x = raw_valid.copy()\n",
    "x.columns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x['pred_std'] = np.std(preds, axis=0)\n",
    "x['pred'] = np.mean(preds, axis=0)\n",
    "x.ProductSize_num.value_counts().plot.barh();\n",
    "#The product size has 6 categories with 1,2,5,6 having very less number of records hence the \n",
    "#std deviation is more and the predictions are not dpendable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flds = ['ProductSize_num', 'pred', 'pred_std']\n",
    "summ = x[flds].groupby(flds[0]).mean()\n",
    "summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Finding the features which are better and retaining only them.\n",
    "def rf_feat_importance(m, df):\n",
    "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
    "                       ).sort_values('imp', ascending=False)\n",
    "#Plotting the R^2 and the importances on a graph can show us the corelation and the values  of importances above which it matters\n",
    "importances = rf_feat_importance(m,X_train)\n",
    "importances.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importances.plot('cols', 'imp', figsize=(10,6), legend=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keeping = (importances[importances['imp'] > 0.005].sort_values('imp',ascending=False))\n",
    "trunc_df = Working_df[keeping.cols]\n",
    "trunc_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_valid = 12000  # same as Kaggle's test set size\n",
    "n_trn = len(trunc_df)-n_valid\n",
    "raw_train, raw_valid = split_vals(trunc_df, n_trn)\n",
    "X_train, X_valid = split_vals(trunc_df, n_trn)\n",
    "y_train, y_valid = split_vals(y, n_trn)\n",
    "\n",
    "X_train.shape, y_train.shape, X_valid.shape,y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##model with truncated features and max_features parameter\n",
    "m = RandomForestRegressor(n_estimators =40,n_jobs=-1,max_features= 0.5)\n",
    "m.fit(X_train,y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.drop(['saleDayofyear','saleWeek','saleDayofweek','saleDay'],axis = 1,inplace=True)\n",
    "X_valid.drop(['saleDayofyear','saleWeek','saleDayofweek','saleDay'],axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = RandomForestRegressor(n_estimators =40,n_jobs=-1,max_features= 0.5)\n",
    "n.fit(X_train,y_train)\n",
    "print_score(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?? rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
